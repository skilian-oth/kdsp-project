{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = \"\"\n",
    "\n",
    "hashtag = \"Hamburg\"\n",
    "dataset_name = hashtag\n",
    "num_tweets = 50\n",
    "allow_retweets = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Make the request to the API\n",
    "# We search for tweets containing the hashtag and their author\n",
    "\n",
    "\n",
    "\n",
    "# Create a folder for the dataset if it doesn't exist\n",
    "try:\n",
    "    import os\n",
    "    os.mkdir(\"data/\" + dataset_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Store the response in a json file\n",
    "def get_tweets(hashtag):\n",
    "\n",
    "    # Create the url\n",
    "    retweet_string = \"\"\n",
    "    if not allow_retweets:\n",
    "        retweet_string = \"%20-is%3Aretweet\"\n",
    "\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query=%23\" + hashtag + retweet_string + \"&max_results=\" + str(num_tweets) + \"&expansions=author_id&tweet.fields=id,created_at,text,author_id,in_reply_to_user_id,public_metrics,possibly_sensitive,lang&user.fields=id,created_at,name,username,protected,verified,profile_image_url,location,url,description,pinned_tweet_id,public_metrics\"\n",
    "    res = requests.get(url, headers={\"Authorization\": \"Bearer \" + bearer_token})\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if (res.json().get(\"errors\")):\n",
    "        print(res.json().get(\"errors\"))\n",
    "\n",
    "    # Save the results to a json file\n",
    "    with open(\"data/\" + dataset_name + \"/response.json\", \"w\") as f:\n",
    "        json.dump(res.json(), f)\n",
    "\n",
    "get_tweets(hashtag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Extract the tweets from the response\n",
    "def extract_tweets(dataset_name):\n",
    "\n",
    "    # Load the json file\n",
    "    with open(\"data/\" + dataset_name + \"/response.json\", encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert the response to a pandas dataframe\n",
    "    res_df = pd.DataFrame(data[\"data\"])\n",
    "    \n",
    "    # Save the dataframe to a csv file\n",
    "    res_df.to_csv(\"data/\" + dataset_name + \"/tweets.csv\", index=False)\n",
    "\n",
    "extract_tweets(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>public_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1050404354887507969</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @melu25: Yo hoy:                Yo el resto...</td>\n",
       "      <td>2022-05-15T14:44:39.000Z</td>\n",
       "      <td>1525849649332080640</td>\n",
       "      <td>{'retweet_count': 3342, 'reply_count': 0, 'lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1507473751033757701</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @senasleyla: Germany watching Spain and Uni...</td>\n",
       "      <td>2022-05-15T14:44:39.000Z</td>\n",
       "      <td>1525849649155870720</td>\n",
       "      <td>{'retweet_count': 1282, 'reply_count': 0, 'lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1239870359807156225</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @Eurovision_ESP: De lo que estoy convencido...</td>\n",
       "      <td>2022-05-15T14:44:39.000Z</td>\n",
       "      <td>1525849648832946176</td>\n",
       "      <td>{'retweet_count': 293, 'reply_count': 0, 'like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703133095</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @Franlamadriddj: Lugar donde ir a partir de...</td>\n",
       "      <td>2022-05-15T14:44:39.000Z</td>\n",
       "      <td>1525849648686153729</td>\n",
       "      <td>{'retweet_count': 2031, 'reply_count': 0, 'lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720669223211679744</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @generalitat: #BenidormFest2023 üèùÔ∏èüé∂\\n\\nüó£Ô∏è @...</td>\n",
       "      <td>2022-05-15T14:44:39.000Z</td>\n",
       "      <td>1525849648497303552</td>\n",
       "      <td>{'retweet_count': 293, 'reply_count': 0, 'like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id lang  possibly_sensitive  \\\n",
       "0  1050404354887507969   es               False   \n",
       "1  1507473751033757701   en               False   \n",
       "2  1239870359807156225   es               False   \n",
       "3            703133095   es               False   \n",
       "4   720669223211679744   es               False   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @melu25: Yo hoy:                Yo el resto...   \n",
       "1  RT @senasleyla: Germany watching Spain and Uni...   \n",
       "2  RT @Eurovision_ESP: De lo que estoy convencido...   \n",
       "3  RT @Franlamadriddj: Lugar donde ir a partir de...   \n",
       "4  RT @generalitat: #BenidormFest2023 üèùÔ∏èüé∂\\n\\nüó£Ô∏è @...   \n",
       "\n",
       "                 created_at                   id  \\\n",
       "0  2022-05-15T14:44:39.000Z  1525849649332080640   \n",
       "1  2022-05-15T14:44:39.000Z  1525849649155870720   \n",
       "2  2022-05-15T14:44:39.000Z  1525849648832946176   \n",
       "3  2022-05-15T14:44:39.000Z  1525849648686153729   \n",
       "4  2022-05-15T14:44:39.000Z  1525849648497303552   \n",
       "\n",
       "                                      public_metrics  \n",
       "0  {'retweet_count': 3342, 'reply_count': 0, 'lik...  \n",
       "1  {'retweet_count': 1282, 'reply_count': 0, 'lik...  \n",
       "2  {'retweet_count': 293, 'reply_count': 0, 'like...  \n",
       "3  {'retweet_count': 2031, 'reply_count': 0, 'lik...  \n",
       "4  {'retweet_count': 293, 'reply_count': 0, 'like...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some tweets in the dataset\n",
    "tweets_file_name = \"data/\" + dataset_name + \"/tweets.csv\"\n",
    "\n",
    "tweets_df = pd.read_csv(tweets_file_name)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Get the authors of the tweets\n",
    "\n",
    "# Call the API to get the authors of the tweets\n",
    "def get_authors(author_id_list):\n",
    "    \n",
    "    # Generate a string of author ids\n",
    "    autor_string = \"\"\n",
    "    for author_id in author_id_list:\n",
    "        autor_string += str(author_id) + \",\"\n",
    "    autor_string = autor_string[:-1] # remove last comma\n",
    "\n",
    "    # request the listed authors to the API\n",
    "    url = \"https://api.twitter.com/2/users?ids=\" + autor_string + \"&user.fields=id,created_at,name,username,verified,profile_image_url,location,description,pinned_tweet_id\"\n",
    "    res = requests.get(url, headers={\"Authorization\": \"Bearer \" + bearer_token})\n",
    "\n",
    "    # Check if there is an error\n",
    "    if res.json().get(\"errors\"):\n",
    "        print(res.json()[\"errors\"])\n",
    "\n",
    "    # convert the response to a dataframe\n",
    "    res_df = pd.DataFrame(res.json()[\"data\"])\n",
    "\n",
    "    # Save the dataframe to a csv file in the right folder\n",
    "    res_df.to_csv(\"data/\" + dataset_name + \"/authors.csv\", index=False)\n",
    "\n",
    "def extract_authors(dataset_name):\n",
    "    \n",
    "    # Load the json file\n",
    "    with open(\"data/\" + dataset_name + \"/response.json\", encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert the response to a pandas dataframe\n",
    "    res_df = pd.DataFrame(data[\"includes\"][\"users\"])\n",
    "\n",
    "    # Save the authors to a csv file\n",
    "    res_df.to_csv(\"data/\" + dataset_name + \"/authors.csv\", index=False)\n",
    "\n",
    "\n",
    "extract_authors(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the tweets authors are in the authors file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1050404354887507969</td>\n",
       "      <td>Marianavarrogu1</td>\n",
       "      <td>Magui üî•</td>\n",
       "      <td>rise up\\n\\nüç∫‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1507473751033757701</td>\n",
       "      <td>FenronF1</td>\n",
       "      <td>FenronF1</td>\n",
       "      <td>Creemos en el plan de Fernando y de Ferrari.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1239870359807156225</td>\n",
       "      <td>lucxjk</td>\n",
       "      <td>üç∏</td>\n",
       "      <td>üëâüëà</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703133095</td>\n",
       "      <td>Alejandra19_98</td>\n",
       "      <td>Ale üåº</td>\n",
       "      <td>historiadora, aunque eso no significa que no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720669223211679744</td>\n",
       "      <td>francescoluigi_</td>\n",
       "      <td>Fran</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id         username      name  \\\n",
       "0  1050404354887507969  Marianavarrogu1   Magui üî•   \n",
       "1  1507473751033757701         FenronF1  FenronF1   \n",
       "2  1239870359807156225           lucxjk         üç∏   \n",
       "3            703133095   Alejandra19_98     Ale üåº   \n",
       "4   720669223211679744  francescoluigi_      Fran   \n",
       "\n",
       "                                         description  \n",
       "0                                      rise up\\n\\nüç∫‚ù§  \n",
       "1  Creemos en el plan de Fernando y de Ferrari.\\n...  \n",
       "2                                                 üëâüëà  \n",
       "3  historiadora, aunque eso no significa que no l...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we know all the authors of the tweets\n",
    "def check_authors(dataset_name):\n",
    "\n",
    "    res = True\n",
    "\n",
    "    # Load the tweets file\n",
    "    tweets_df = pd.read_csv(\"data/\" + dataset_name + \"/tweets.csv\")\n",
    "\n",
    "    # Get the list of author ids\n",
    "    author_id_list = tweets_df[\"author_id\"].unique()\n",
    "\n",
    "    # Check if the authors are in the authors file\n",
    "    authors_df = pd.read_csv(\"data/\" + dataset_name + \"/authors.csv\")\n",
    "\n",
    "    for author_id in author_id_list:\n",
    "        if author_id not in authors_df[\"id\"].unique():\n",
    "            print(\"Author id \" + str(author_id) + \" not found in the authors file\")\n",
    "            res = False\n",
    "\n",
    "    if (res):\n",
    "        print(\"All the tweets authors are in the authors file\")\n",
    "\n",
    "\n",
    "# Import the athors from the file\n",
    "authors_df = pd.read_csv(\"data/\" + dataset_name + \"/authors.csv\")\n",
    "\n",
    "# Print some of the dataframe\n",
    "check_authors(dataset_name)\n",
    "authors_df[[\"id\", \"username\", \"name\", \"description\"]].head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
