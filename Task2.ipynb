{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Top 10 hash tags and users based on their number of tweets in your data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a key to a dictionary if it doesn't exist yet\n",
    "def addToDict(hashtags, hash):\n",
    "    if (hash in hashtags):\n",
    "        hashtags[hash] += 1\n",
    "    else:\n",
    "        hashtags[hash] = 1\n",
    "\n",
    "# Parse a tweet and add the hashtags to the hashtags dictionary\n",
    "def parse_tweet_for_hashtags(hashtags, tweet):\n",
    "    \n",
    "    # List of characters that ends a hashtag\n",
    "    invalid_chars = [',', '.', '!', '?', ':', ';', '\"', '#', '\\'', '\\\\', '/', '|', '@', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '{', '}', '[', ']', '<', '>', '~', '`', ' ', '\\n', '\\t', '\\xa0']\n",
    "    \n",
    "    parsing_hashtag = False # State value to know if we are currently parsing a hashtag or not\n",
    "    hashtag = \"\" # The hashtag we are parsing\n",
    "    for letter in tweet:\n",
    "\n",
    "        # Begin parsing a hashtag\n",
    "        if letter == \"#\":\n",
    "            parsing_hashtag = True\n",
    "            hashtag += letter\n",
    "\n",
    "        # End parsing a hashtag\n",
    "        elif parsing_hashtag and letter in invalid_chars:\n",
    "            parsing_hashtag = False\n",
    "            addToDict(hashtags, hashtag)\n",
    "            hashtag = \"\"\n",
    "\n",
    "        # Continue parsing a hashtag\n",
    "        elif parsing_hashtag:\n",
    "            hashtag += letter\n",
    "\n",
    "        # Not parsing a hashtag\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # If the tweet ended with a hashtag, add it to the hashtags dictionary\n",
    "    if parsing_hashtag:\n",
    "        addToDict(hashtags, hashtag)\n",
    "\n",
    "# Return a dictionary with the hashtags and their counts\n",
    "def get_hashtags(datasets):\n",
    "\n",
    "    # Create a dictionary to store the hashtags and their counts\n",
    "    hashtags = {} \n",
    "\n",
    "    for dataset in datasets: # For each dataset\n",
    "\n",
    "        # Read the tweets file\n",
    "        tweets_df = pd.read_csv(\"data/\" + dataset + \"/tweets.csv\")\n",
    "\n",
    "        for tweet in tweets_df['text']: # For each tweet\n",
    "            parse_tweet_for_hashtags(hashtags, tweet)\n",
    "    \n",
    "    return hashtags\n",
    "\n",
    "# Fill a dictionary with the number of tweets per author\n",
    "def get_author_ids(datasets):\n",
    "    authors = {} # Create a dictionary to store the authors and their counts\n",
    "    for dataset in datasets:\n",
    "        tweets_df = pd.read_csv(\"data/\" + dataset + \"/tweets.csv\")\n",
    "        for author in tweets_df['author_id']:\n",
    "            addToDict(authors, author)\n",
    "    return authors\n",
    "\n",
    "# Return the author with the given id\n",
    "def author_by_id(id, datasets):\n",
    "    for dataset in datasets:\n",
    "        authors_df = pd.read_csv(\"data/\" + dataset + \"/authors.csv\")\n",
    "        author = authors_df[authors_df['id'] == id]\n",
    "        if len(author) > 0:\n",
    "            return author\n",
    "            \n",
    "    return None\n",
    "\n",
    "# Return the top 10 keys and values in a dictionary, sorted by value\n",
    "def top10(dict):\n",
    "    sorted_dict = sorted(dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_dict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 10 hashtags in the given datasets\n",
    "def print_top_10_hashtags(datasets):\n",
    "\n",
    "    # Get the hashtags and their counts\n",
    "    hashtags = get_hashtags(datasets)\n",
    "\n",
    "    # Get the top 10 hashtags\n",
    "    top = top10(hashtags)\n",
    "\n",
    "    # Print the top 10 hashtags\n",
    "    print(\"Top 10 hashtags:\")\n",
    "    for i in range(10):\n",
    "        print(1 + i, \":\", top[i][0], \":\", top[i][1])\n",
    "\n",
    "# Print the top 10 authors in the given datasets\n",
    "def print_top_10_authors(datasets):\n",
    "\n",
    "    # Get the authors and their counts\n",
    "    authors_id = get_author_ids(datasets)\n",
    "\n",
    "    # Get the top 10 authors\n",
    "    top = top10(authors_id)\n",
    "\n",
    "    # Print the top 10 authors\n",
    "    print(\"Top 10 authors:\")\n",
    "    for i in range(10):\n",
    "        author = author_by_id(top[i][0], datasets)\n",
    "        print(1 + i, \" : \", author['name'].values[0], \" (@\", author['username'].values[0], \") : \", top[i][1], sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hashtags:\n",
      "1 : #Paris : 1003\n",
      "2 : #paris : 484\n",
      "3 : #France : 170\n",
      "4 : #london : 90\n",
      "5 : #france : 80\n",
      "6 : #Marseille : 80\n",
      "7 : #Toulouse : 76\n",
      "8 : #DLP : 75\n",
      "9 : #Berlin : 67\n",
      "10 : #London : 65\n",
      "\n",
      "\n",
      "Top 10 authors:\n",
      "1 : DLP Stats (@DlpStats) : 56\n",
      "2 : Nabaat (@Nahbaat) : 51\n",
      "3 : Paris d'autrefois (@ParisAntan) : 42\n",
      "4 : Radio75.org // Xv3radio18.com (@Xv3Radio75) : 29\n",
      "5 : SmoothJazzNola (@smoothjazznola) : 28\n",
      "6 : Chicago Secret Society (@Chicago________) : 19\n",
      "7 : Valurank (@valurank) : 16\n",
      "8 : Dimitra Kourkoulakou (@dkourkoulakou) : 16\n",
      "9 : Paris Liebe (@liebe_paris) : 15\n",
      "10 : Doffou Radio Bordeaux (@DoffouRadio) : 12\n"
     ]
    }
   ],
   "source": [
    "# Get the hashtags and their counts\n",
    "datasets = [\"Paris\"]\n",
    "print_top_10_hashtags(datasets)\n",
    "print(\"\\n\")\n",
    "print_top_10_authors(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e09f832a1894402aebfc063e92f06be1b97c67226102314a93108d0e0d545b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
