{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\saphy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "\n",
    "bearer_token = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 : Derive the sentiment of each tweet using Python module (no need to create your Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7783</td>\n",
       "      <td>#Europe #jetfuel even Europe bouncing back&amp;gt;\\n\\nRegional air traffic was back to 85.5% of pre-pandemic levels this week, according to network manager Eurocontrol, with fuel uplift now showing a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Prime Minister of #Estonia. #Sweden #NATO #Europe https://t.co/Ah3euQrPLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2960</td>\n",
       "      <td>Breaking: Sweden will submit an application to join NATO\\n\\n#nato #sweden #Finland #europe #UkraineRussianWar #NATO #balticsea https://t.co/Ydj8jU98yg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8316</td>\n",
       "      <td>Eurovision‚Äôs biggest surprise? UK seems to be popular in Europe #bitcoin #Eurovisions #biggest #surprise #popular¬†#Europe https://t.co/uGCJLgkWnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Moi je ne suis pas trop s√ªre que les sanctions n'isolent pas plut√¥t l'#Europe? Quelques grandes puissances europ√©ennes vont peut-√™tre s'en sortir mais d'autres, moins s√ªr. Par contre la poign√©e d'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>All this #fascist of the Nordic Resistance are also just defending their values and countries ... Right?\\nNo surprise they attended #Azov Camps over the last yrs and now fight together with the fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Outside Roman Colosseum \\n\\n#colosseum #gladiator #rome #ancientrome #Rome #VaticanCity #travel #europe #vacation  #italy #traveller  #placestovisit @ Roman Colosseum https://t.co/I13cWhzRwP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.1027</td>\n",
       "      <td>A ‚Äúperfect winter storm‚Äù may be forming in #Europe, as the continent seeks to limit Russian gas flows, analysts at #RystadEnergy said in a press release this week. They added there might be not en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3182</td>\n",
       "      <td>@KM88334862 Top 6 Uganda Day Tours, Trips and Short Excursions\\nhttps://t.co/5sZbjxjwCe #daytrip #Exclusive short excursions #UnitedStates #Ukraine #Finland #France #Albania #Denmark #Switzerland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>#international #world #global #earth #europe #rwc2022 #RetinaWcongress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>#Ukraine #USA #Europe #Putin #Russia #Russian #Russianculture #RussianWarCrimes #RussianUkrainianWar #RussiaUkraineCrisis #rt #ntv #tass #Bitcoin #Ethereum #InuSaitama #Binance #shibainu #dogecoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>üö®‚òéÔ∏è DONE DEAL : #Suarez et @Atleti c'est termin√© ‚ùåÔ∏è\\n\\nIl quittera @Atleti √† l'issue de la saison ‚úÖÔ∏è‚úçÔ∏èüîö\\n\\nIl avait des options de #MLS mais il restera en #Europe comme confirm√© par @MatteMoretto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>https://t.co/091UtHXIFZ - One thing I will say. Tyranny does rhyme with Russia. Huh. #russia #politics #ukraine #society #ironcurtain #sovietunion #china #europe #germany #german #rammstein #europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>I passed. #American #America #presidentoftheusa #presidentpaul #aliens #CIPOTUSOA #gaming #777 #homework #videogames #Florida #europe #southflorida #cat #dog #420 #history https://t.co/4EQ9EbNsj1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>@RassNational53 @JulienOdoul Car si c‚Äôest l‚Äô #Ukraine rien , absolument rien n‚Äôest un probl√®me, c‚Äôest l‚Äô #OTAN , l‚Äô #Europe et #JoeBiden qui l‚Äôont dit ‚Ä¶ https://t.co/ih6uC1RUPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7845</td>\n",
       "      <td>@Verisk3E has an upcoming webinar May 26th - Best Practices in EHS Support for Retail and Distribution  Check it out - https://t.co/ZdqUi1nQMC\\n#EHS #europe #hazcom #transport #retail #distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>@MarcotheLuck 3 Days Honeymoon Ngamba Island Tour Package\\nhttps://t.co/KRVV8QVDWB\\n#travelwithkabira #travelphotography #WritingCommunity #UnitedStates #Ukraine #Finland #France #Albania #Denmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Br√≤g na cuthaige #coille #brocan #bluebells #ayrshire #scotland #europe https://t.co/lpfKcYnXYH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>For Americans, this will be the best year to visit #Europe in years, if not decades.\\n\\nHere's why: https://t.co/XfIS8JeFdq https://t.co/5ZtgxsAdTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Always crowded Piazza di Spagna, #Rome, #Italy üáÆüáπ - üì∏ Photo ¬© by marina.cleo üôåüèÜ #Europe #European #streetphotography #travel #Wanderlust #beautifuldestinations https://t.co/yBtMPelwXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  \\\n",
       "0      0.7783   \n",
       "1      0.0000   \n",
       "2      0.2960   \n",
       "3      0.8316   \n",
       "4      0.0000   \n",
       "5      0.0000   \n",
       "6      0.0000   \n",
       "7     -0.1027   \n",
       "8      0.3182   \n",
       "9      0.0000   \n",
       "10     0.4939   \n",
       "11     0.0000   \n",
       "12     0.0000   \n",
       "13     0.0000   \n",
       "14     0.0000   \n",
       "15     0.7845   \n",
       "16     0.0000   \n",
       "17     0.0000   \n",
       "18     0.6369   \n",
       "19     0.0000   \n",
       "\n",
       "                                                                                                                                                                                                       text  \n",
       "0   #Europe #jetfuel even Europe bouncing back&gt;\\n\\nRegional air traffic was back to 85.5% of pre-pandemic levels this week, according to network manager Eurocontrol, with fuel uplift now showing a ...  \n",
       "1                                                                                                                                 Prime Minister of #Estonia. #Sweden #NATO #Europe https://t.co/Ah3euQrPLN  \n",
       "2                                                    Breaking: Sweden will submit an application to join NATO\\n\\n#nato #sweden #Finland #europe #UkraineRussianWar #NATO #balticsea https://t.co/Ydj8jU98yg  \n",
       "3                                                         Eurovision‚Äôs biggest surprise? UK seems to be popular in Europe #bitcoin #Eurovisions #biggest #surprise #popular¬†#Europe https://t.co/uGCJLgkWnu  \n",
       "4   Moi je ne suis pas trop s√ªre que les sanctions n'isolent pas plut√¥t l'#Europe? Quelques grandes puissances europ√©ennes vont peut-√™tre s'en sortir mais d'autres, moins s√ªr. Par contre la poign√©e d'...  \n",
       "5   All this #fascist of the Nordic Resistance are also just defending their values and countries ... Right?\\nNo surprise they attended #Azov Camps over the last yrs and now fight together with the fa...  \n",
       "6            Outside Roman Colosseum \\n\\n#colosseum #gladiator #rome #ancientrome #Rome #VaticanCity #travel #europe #vacation  #italy #traveller  #placestovisit @ Roman Colosseum https://t.co/I13cWhzRwP  \n",
       "7   A ‚Äúperfect winter storm‚Äù may be forming in #Europe, as the continent seeks to limit Russian gas flows, analysts at #RystadEnergy said in a press release this week. They added there might be not en...  \n",
       "8   @KM88334862 Top 6 Uganda Day Tours, Trips and Short Excursions\\nhttps://t.co/5sZbjxjwCe #daytrip #Exclusive short excursions #UnitedStates #Ukraine #Finland #France #Albania #Denmark #Switzerland ...  \n",
       "9                                                                                                                                    #international #world #global #earth #europe #rwc2022 #RetinaWcongress  \n",
       "10  #Ukraine #USA #Europe #Putin #Russia #Russian #Russianculture #RussianWarCrimes #RussianUkrainianWar #RussiaUkraineCrisis #rt #ntv #tass #Bitcoin #Ethereum #InuSaitama #Binance #shibainu #dogecoin...  \n",
       "11  üö®‚òéÔ∏è DONE DEAL : #Suarez et @Atleti c'est termin√© ‚ùåÔ∏è\\n\\nIl quittera @Atleti √† l'issue de la saison ‚úÖÔ∏è‚úçÔ∏èüîö\\n\\nIl avait des options de #MLS mais il restera en #Europe comme confirm√© par @MatteMoretto ...  \n",
       "12  https://t.co/091UtHXIFZ - One thing I will say. Tyranny does rhyme with Russia. Huh. #russia #politics #ukraine #society #ironcurtain #sovietunion #china #europe #germany #german #rammstein #europ...  \n",
       "13      I passed. #American #America #presidentoftheusa #presidentpaul #aliens #CIPOTUSOA #gaming #777 #homework #videogames #Florida #europe #southflorida #cat #dog #420 #history https://t.co/4EQ9EbNsj1  \n",
       "14                         @RassNational53 @JulienOdoul Car si c‚Äôest l‚Äô #Ukraine rien , absolument rien n‚Äôest un probl√®me, c‚Äôest l‚Äô #OTAN , l‚Äô #Europe et #JoeBiden qui l‚Äôont dit ‚Ä¶ https://t.co/ih6uC1RUPR  \n",
       "15  @Verisk3E has an upcoming webinar May 26th - Best Practices in EHS Support for Retail and Distribution  Check it out - https://t.co/ZdqUi1nQMC\\n#EHS #europe #hazcom #transport #retail #distributio...  \n",
       "16  @MarcotheLuck 3 Days Honeymoon Ngamba Island Tour Package\\nhttps://t.co/KRVV8QVDWB\\n#travelwithkabira #travelphotography #WritingCommunity #UnitedStates #Ukraine #Finland #France #Albania #Denmark...  \n",
       "17                                                                                                          Br√≤g na cuthaige #coille #brocan #bluebells #ayrshire #scotland #europe https://t.co/lpfKcYnXYH  \n",
       "18                                                      For Americans, this will be the best year to visit #Europe in years, if not decades.\\n\\nHere's why: https://t.co/XfIS8JeFdq https://t.co/5ZtgxsAdTP  \n",
       "19                  Always crowded Piazza di Spagna, #Rome, #Italy üáÆüáπ - üì∏ Photo ¬© by marina.cleo üôåüèÜ #Europe #European #streetphotography #travel #Wanderlust #beautifuldestinations https://t.co/yBtMPelwXY  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Europe\"\n",
    "pd.options.display.max_colwidth = 200 #Increase the size of the output\n",
    "\n",
    "# Remove unwanted symbols\n",
    "def clean_tweet(tweet):\n",
    "    return tweet.replace(\"#\", \"\").replace(\"@\", \"\").replace(\"RT\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "# Import the tweets dataframe\n",
    "tweets_df = pd.read_csv(\"data/\" + dataset_name + \"/tweets.csv\")\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assig a sentiment variable to the tweets dataframe\n",
    "tweets_df['sentiment'] = tweets_df['text'].apply(lambda x: analyser.polarity_scores(clean_tweet(x))['compound'])\n",
    "tweets_df[['sentiment', 'text']].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Top 10 hash tags and users based on their number of tweets in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hashtags:\n",
      "1 : #Europe : 40\n",
      "2 : #europe : 10\n",
      "3 : #Ukraine : 10\n",
      "4 : #travel : 8\n",
      "5 : #UnitedStates : 8\n",
      "6 : #Germany : 6\n",
      "7 : #USA : 6\n",
      "8 : #America : 6\n",
      "9 : #Sweden : 5\n",
      "10 : #Finland : 5\n",
      "\n",
      "\n",
      "Top 10 authors:\n",
      "1 : Kabira Gorilla Trekking Safaris (@gorillakabira) : 5\n",
      "2 : Valurank (@valurank) : 3\n",
      "3 : The Traveling Types (@type_traveling) : 2\n",
      "4 : AAGGAGAT (@AAGGAGAT1) : 2\n",
      "5 : ÿπÿ®ÿØÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑÿ∑ÿπŸäÿ≥ ÿßŸÑÿßÿ≥ŸáŸÖ ŸàÿßŸÑÿπŸÖŸÑÿßÿ™ üá∫üá∏ (@red6660d) : 2\n",
      "6 : Mcryptoz (@McryptozCom) : 2\n",
      "7 : Tracy (ùïÆùñçùñé) (@chigrl) : 1\n",
      "8 : Shane Woodford (@WoodfordinDK) : 1\n",
      "9 : Lars (@Norrtillsoder) : 1\n",
      "10 : Car (@carwaxo) : 1\n"
     ]
    }
   ],
   "source": [
    "# Add a key to a dictionary if it doesn't exist yet\n",
    "def addToDict(hashtags, hash):\n",
    "    if (hash in hashtags):\n",
    "        hashtags[hash] += 1\n",
    "    else:\n",
    "        hashtags[hash] = 1\n",
    "\n",
    "# Parse a tweet and add the hashtags to the dictionary\n",
    "def parse_tweet_for_hashtags(hashtags, tweet):\n",
    "    \n",
    "    # List of ending characters\n",
    "    invalid_chars = [',', '.', '!', '?', ':', ';', '\"', '#', '\\'', '\\\\', '/', '|', '@', '$', '%', '^', '&', '*', '(', ')', '_', '+', '=', '{', '}', '[', ']', '<', '>', '~', '`', ' ', '\\n', '\\t', '\\xa0']\n",
    "    \n",
    "    parsing_hashtag = False # State value to know if we are parsing a hashtag or not\n",
    "    hashtag = \"\" # The hashtag we are parsing\n",
    "    for letter in tweet:\n",
    "\n",
    "        # Begin parsing a hashtag\n",
    "        if letter == \"#\":\n",
    "            parsing_hashtag = True\n",
    "            hashtag += letter\n",
    "\n",
    "        # End parsing a hashtag\n",
    "        elif parsing_hashtag and letter in invalid_chars:\n",
    "            parsing_hashtag = False\n",
    "            addToDict(hashtags, hashtag)\n",
    "            hashtag = \"\"\n",
    "\n",
    "        # Continue parsing a hashtag\n",
    "        elif parsing_hashtag:\n",
    "            hashtag += letter\n",
    "\n",
    "        # Not parsing a hashtag\n",
    "        else:\n",
    "            continue\n",
    "    # Add the last hashtag, if it exists\n",
    "    if parsing_hashtag:\n",
    "        addToDict(hashtags, hashtag)\n",
    "\n",
    "# Fill a dictionary with the hashtags and their counts\n",
    "def get_hashtags(datasets):\n",
    "\n",
    "    hashtags = {} # Create a dictionary to store the hashtags and their counts\n",
    "    for dataset in datasets:\n",
    "        tweets_df = pd.read_csv(\"data/\" + dataset + \"/tweets.csv\")\n",
    "        for tweet in tweets_df['text']:\n",
    "            parse_tweet_for_hashtags(hashtags, tweet)\n",
    "    return hashtags\n",
    "\n",
    "# Fill a dictionary with the number of tweets per author\n",
    "def get_author_ids(datasets):\n",
    "    authors = {} # Create a dictionary to store the authors and their counts\n",
    "    for dataset in datasets:\n",
    "        tweets_df = pd.read_csv(\"data/\" + dataset + \"/tweets.csv\")\n",
    "        for author in tweets_df['author_id']:\n",
    "            addToDict(authors, author)\n",
    "    return authors\n",
    "\n",
    "def author_by_id(id, datasets):\n",
    "    for dataset in datasets:\n",
    "        authors_df = pd.read_csv(\"data/\" + dataset + \"/authors.csv\")\n",
    "        author = authors_df[authors_df['id'] == id]\n",
    "        if len(author) > 0:\n",
    "            return author\n",
    "            \n",
    "    return None\n",
    "\n",
    "# Sort the hashtags by their counts and return the top 10\n",
    "def top10(dict):\n",
    "    sorted_dict = sorted(dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_dict[:10]\n",
    "\n",
    "def print_top_10_hashtags(datasets):\n",
    "    hashtags = get_hashtags(datasets)\n",
    "    top = top10(hashtags)\n",
    "    print(\"Top 10 hashtags:\")\n",
    "    for i in range(10):\n",
    "        print(1 + i, \":\", top[i][0], \":\", top[i][1])\n",
    "\n",
    "def print_top_10_authors(datasets):\n",
    "    authors_id = get_author_ids(datasets)\n",
    "    top = top10(authors_id)\n",
    "    print(\"Top 10 authors:\")\n",
    "    for i in range(10):\n",
    "        author = author_by_id(top[i][0], datasets)\n",
    "        print(1 + i, \" : \", author['name'].values[0], \" (@\", author['username'].values[0], \") : \", top[i][1], sep=\"\")\n",
    "    \n",
    "\n",
    "\n",
    "# Get the hashtags and their counts\n",
    "datasets = [\"Europe\"]\n",
    "\n",
    "print_top_10_hashtags(datasets)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print_top_10_authors(datasets)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 : Get the followers of a given twitter user from your acquired data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_id_by_username(username, datasets):\n",
    "\n",
    "    # Remove the @ symbol\n",
    "    username = username.replace(\"@\", \"\")\n",
    "\n",
    "    # Look for the user in the datasets\n",
    "    for dataset in datasets:\n",
    "        authors_df = pd.read_csv(\"data/\" + dataset + \"/authors.csv\")\n",
    "        author = authors_df[authors_df['username'] == username]\n",
    "        if len(author) > 0:\n",
    "            return author['id'].values[0]\n",
    "    return None\n",
    "\n",
    "def get_followers(user_id, max_results):\n",
    "    #url = \"https://api.twitter.com/2/users/\" + str(user_id) + \"/followers?max_results=\" + str(max_results)\n",
    "    url = \"https://api.twitter.com/2/users/2244994945/followers?user.fields=id,created_at,name,username,protected,verified,profile_image_url,location,url,description,pinned_tweet_id,public_metrics\"\n",
    "    res = requests.get(url, headers={\"Authorization\": \"Bearer \" + bearer_token})\n",
    "\n",
    "    # Check if there is an error\n",
    "    if (res.json().get(\"errors\")):\n",
    "        print(\"Error:\", res.json()[\"errors\"])\n",
    "        return None\n",
    "\n",
    "    # Convert the response to a dataframe\n",
    "    followers_df = pd.DataFrame(res.json()[\"data\"])\n",
    "\n",
    "    # Save the dataframe to a csv file\n",
    "    followers_df.to_csv(\"data/followers/\" + str(user_id) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighLevelsLeadershipsüåçDirecteur üá´üá∑</td>\n",
       "      <td>2016-12-25T19:59:51.000Z</td>\n",
       "      <td>industry140</td>\n",
       "      <td>813112037635223554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AarojassajoraA</td>\n",
       "      <td>2021-07-29T09:46:25.000Z</td>\n",
       "      <td>ManuelAarnRoja2</td>\n",
       "      <td>1420682034729656327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÿ¨ÿßÿ≥ŸÖ</td>\n",
       "      <td>2019-04-28T00:38:53.000Z</td>\n",
       "      <td>2W9r9yDMq0epYYt</td>\n",
       "      <td>1122299109854019585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Idowu Adesoji</td>\n",
       "      <td>2022-04-28T12:21:02.000Z</td>\n",
       "      <td>SojiIdowu06</td>\n",
       "      <td>1519652428219568134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hut Ho van</td>\n",
       "      <td>2022-05-15T17:22:31.000Z</td>\n",
       "      <td>hutakak</td>\n",
       "      <td>1525889297907593218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>‡§∏‡§æ‡§Ç‡§ï?</td>\n",
       "      <td>2022-02-27T15:41:17.000Z</td>\n",
       "      <td>sanka01811857</td>\n",
       "      <td>1497959993772892161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>thanh dan</td>\n",
       "      <td>2022-02-28T08:46:01.000Z</td>\n",
       "      <td>thanhdandan12</td>\n",
       "      <td>1498217873206288384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tien Dat</td>\n",
       "      <td>2021-12-16T16:34:12.000Z</td>\n",
       "      <td>TienDat0901</td>\n",
       "      <td>1471518978023432199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ti·∫øn Nguy·ªÖn</td>\n",
       "      <td>2021-12-16T16:21:20.000Z</td>\n",
       "      <td>Tiennguyen2231</td>\n",
       "      <td>1471515743707566093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Poooo</td>\n",
       "      <td>2022-03-22T19:27:53.000Z</td>\n",
       "      <td>from_poooo</td>\n",
       "      <td>1506351912488431617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name                created_at  \\\n",
       "0   HighLevelsLeadershipsüåçDirecteur üá´üá∑  2016-12-25T19:59:51.000Z   \n",
       "1                       AarojassajoraA  2021-07-29T09:46:25.000Z   \n",
       "2                                 ÿ¨ÿßÿ≥ŸÖ  2019-04-28T00:38:53.000Z   \n",
       "3                        Idowu Adesoji  2022-04-28T12:21:02.000Z   \n",
       "4                           Hut Ho van  2022-05-15T17:22:31.000Z   \n",
       "..                                 ...                       ...   \n",
       "95                               ‡§∏‡§æ‡§Ç‡§ï?  2022-02-27T15:41:17.000Z   \n",
       "96                           thanh dan  2022-02-28T08:46:01.000Z   \n",
       "97                            Tien Dat  2021-12-16T16:34:12.000Z   \n",
       "98                         Ti·∫øn Nguy·ªÖn  2021-12-16T16:21:20.000Z   \n",
       "99                               Poooo  2022-03-22T19:27:53.000Z   \n",
       "\n",
       "           username                   id  \n",
       "0       industry140   813112037635223554  \n",
       "1   ManuelAarnRoja2  1420682034729656327  \n",
       "2   2W9r9yDMq0epYYt  1122299109854019585  \n",
       "3       SojiIdowu06  1519652428219568134  \n",
       "4           hutakak  1525889297907593218  \n",
       "..              ...                  ...  \n",
       "95    sanka01811857  1497959993772892161  \n",
       "96    thanhdandan12  1498217873206288384  \n",
       "97      TienDat0901  1471518978023432199  \n",
       "98   Tiennguyen2231  1471515743707566093  \n",
       "99       from_poooo  1506351912488431617  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [\"Europe\"]\n",
    "id = user_id_by_username(\"@gorillakabira\", datasets)\n",
    "get_followers(id, 10)\n",
    "\n",
    "followers_df = pd.read_csv(\"data/followers/\" + str(id) + \".csv\")\n",
    "followers_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e09f832a1894402aebfc063e92f06be1b97c67226102314a93108d0e0d545b4b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
